{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning POC: Chest X-ray with ConvNet2\n",
    "\n",
    "This notebook demonstrates a federated learning setup using NVFlare to train the `ConvNet2` model (or the LoRA-optimized version) on the Chest X-ray dataset distributed across 3 sites (`site1`, `site2`, `site3`).\n",
    "\n",
    "## Objectives:\n",
    "1. **Pre-train** the backbone on a small data subset to initialize the global model.\n",
    "2. Compare **Full Fine-tuning** vs **LoRA** (Low-Rank Adaptation).\n",
    "3. Use **Mixed Precision** training for faster execution.\n",
    "4. Simulate 3 federated sites with `FedAvg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, datasets\n",
    "from model import ConvNet2, LoRAConvNet2\n",
    "import numpy as np",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-training Initialization\n",
    "\n",
    "Instead of starting with random weights, we pre-train the model backbone on a small subset of the training data (e.g., from site 1). This stable initialization helps with convergence in federated environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrain_loader(data_path, batch_size=16, num_samples=100):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2]),\n",
    "    ])\n",
    "    \n",
    "    # Use site1 training data for pre-training\n",
    "    site1_train_path = os.path.join(data_path, \"site1\", \"train\")\n",
    "    full_dataset = datasets.ImageFolder(root=site1_train_path, transform=transform)\n",
    "    \n",
    "    # Take a small subset\n",
    "    indices = np.random.choice(len(full_dataset), num_samples, replace=False)\n",
    "    subset = Subset(full_dataset, indices)\n",
    "    \n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def pretrain_model(model, loader, epochs=2, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Pre-train Epoch {epoch+1} Loss: {running_loss/len(loader):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "data_path = os.path.abspath(\"chest_xray\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"---- Starting Pre-training Initialization ----\")\n",
    "base_model = ConvNet2()\n",
    "pretrain_loader = get_pretrain_loader(data_path)\n",
    "initialized_model = pretrain_model(base_model, pretrain_loader, device=device)\n",
    "print(\"---- Pre-training Done ----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the FedJob Recipe\n",
    "\n",
    "We can now choose between the **Full** model or the **LoRA** model. \n",
    "\n",
    "### Choice: LoRA vs Full\n",
    "Change `USE_LORA` to `True` to use the Low-Rank Adaptation model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvflare.app_opt.pt.recipes.fedavg import FedAvgRecipe\n",
    "from nvflare.recipe import SimEnv, add_experiment_tracking\n",
    "\n",
    "USE_LORA = True # Set to False for Full fine-tuning\n",
    "USE_AMP = True\n",
    "n_clients = 3\n",
    "num_rounds = 5\n",
    "batch_size = 16\n",
    "\n",
    "if USE_LORA:\n",
    "    # Wrap the pre-trained weights into LoRA model\n",
    "    model_to_run = LoRAConvNet2(rank=8, base_model=initialized_model)\n",
    "    model_type = \"lora\"\n",
    "    job_name = \"chest-xray-lora\"\n",
    "else:\n",
    "    model_to_run = initialized_model\n",
    "    model_type = \"full\"\n",
    "    job_name = \"chest-xray-full\"\n",
    "\n",
    "recipe = FedAvgRecipe(\n",
    "    name=job_name,\n",
    "    min_clients=n_clients,\n",
    "    num_rounds=num_rounds,\n",
    "    model=model_to_run,\n",
    "    train_script=\"client_xray.py\",\n",
    "    train_args=f\"--batch_size {batch_size} --epochs 1 --data_path {data_path} --model_type {model_type} --use_amp {USE_AMP}\",\n",
    ")\n",
    "\n",
    "add_experiment_tracking(recipe, tracking_type=\"tensorboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Job in Simulation\n",
    "\n",
    "We will now execute the federated learning job across 3 simulated clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimEnv(num_clients=n_clients)\n",
    "print(f\"---- Starting {job_name} Experiment ----\")\n",
    "start_time_lora = time.time()\n",
    "run = recipe.execute(env)\n",
    "end_time_lora = time.time()\n",
    "duration_lora = end_time_lora - start_time_lora\n",
    "\n",
    "print()\n",
    "print(\"Job Status is:\", run.get_status())\n",
    "print(f\"Experiment duration: {duration_lora:.2f} seconds\")\n",
    "print(\"Result can be found in :\", run.get_result())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the results\n",
    "\n",
    "Launch TensorBoard to see the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison: Normal Federated Learning (Full Fine-tuning)\n",
    "\n",
    "To understand the impact of LoRA, we'll also run a standard Federated Learning job where all parameters are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "print(\"---- Starting Full Federated Learning Comparison ----\")\n",
    "# Reset to full model\n",
    "full_model_init = copy.deepcopy(initialized_model)\n",
    "job_name_full = \"chest-xray-full-comparison\"\n",
    "\n",
    "recipe_full = FedAvgRecipe(\n",
    "    name=job_name_full,\n",
    "    min_clients=n_clients,\n",
    "    num_rounds=num_rounds,\n",
    "    model=full_model_init,\n",
    "    train_script=\"client_xray.py\",\n",
    "    train_args=f\"--batch_size {batch_size} --epochs 1 --data_path {data_path} --model_type full --use_amp {USE_AMP}\",\n",
    ")\n",
    "\n",
    "add_experiment_tracking(recipe_full, tracking_type=\"tensorboard\")\n",
    "\n",
    "start_time_full = time.time()\n",
    "run_full = recipe_full.execute(env)\n",
    "end_time_full = time.time()\n",
    "duration_full = end_time_full - start_time_full\n",
    "\n",
    "print(\"Full FL Job Status:\", run_full.get_status())\n",
    "print(f\"Experiment duration: {duration_full:.2f} seconds\")\n",
    "print(\"Full FL Result:\", run_full.get_result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --bind_all --logdir /tmp/nvflare/simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\n---- FINAL COMPARISON SUMMARY ----\")\n",
    "data = {\n",
    "    \"Experiment\": [\"LoRA Federated Learning\", \"Full Federated Learning\"],\n",
    "    \"Method\": [\"LoRA (Low-Rank Adaptation)\", \"Full Parameter Tuning\"],\n",
    "    \"Duration (sec)\": [round(duration_lora, 2), round(duration_full, 2)],\n",
    "    \"Est. Communication\": [\"Low (~1% params)\", \"High (100% params)\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}